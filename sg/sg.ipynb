{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## Graph Neural Networks with Pytorch\r\n",
                "## Target: Simplifying Graph Convolutional Networks\r\n",
                "- Original Paper: https://arxiv.org/abs/1902.07153\r\n",
                "- Original Code: https://github.com/rusty1s/pytorch_geometric/blob/master/examples/sgc.py"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\r\n",
                "import sys\r\n",
                "\r\n",
                "import torch\r\n",
                "import torch.nn.functional as F\r\n",
                "from torch_geometric.datasets import Planetoid\r\n",
                "from torch_geometric.nn import SGConv\r\n",
                "\r\n",
                "sys.path.append('../')\r\n",
                "from utils import *\r\n",
                "logger = make_logger(name='sg_logger')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "# Load Dataset\r\n",
                "dataset = 'Cora'\r\n",
                "path = os.path.join(os.getcwd(), '..', 'data', dataset)\r\n",
                "dataset = Planetoid(path, dataset)\r\n",
                "data = dataset[0]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "class SG(torch.nn.Module):\r\n",
                "    def __init__(self):\r\n",
                "        super(SG, self).__init__()\r\n",
                "        self.conv1 = SGConv(\r\n",
                "            dataset.num_features, dataset.num_classes, K=2, cached=True)\r\n",
                "\r\n",
                "    def forward(self):\r\n",
                "        x, edge_index = data.x, data.edge_index\r\n",
                "        x = self.conv1(x, edge_index)\r\n",
                "        return F.log_softmax(x, dim=1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Simplfied Graph Convolutional Networks**는 기존의 **GCN**에서 많은 시간을 소요하게 만들었던 활성화 함수를 상당 부분 생략함으로써,  \r\n",
                "속도 향상과 더불어 성능 유지라는 두마리 토끼를 다 잡을 수 있다는 사실을 증명한 방법론이다.  \r\n",
                "\r\n",
                "**SGConv** Layer는 아래와 같이 구성된다.  \r\n",
                "\r\n",
                "$$ \\mathbf{H}^{`} = (\\mathbf{D}^{-0.5} \\hat{\\mathbf{A}} \\mathbf{D}^{0.5})^{K} \\mathbf{H} \\mathbf{W} $$  \r\n",
                "\r\n",
                "위 식에서 $K$ 는 총 Layer의 수를 의미한다.  \r\n",
                "\r\n",
                "`Adjacency Matrix`를 활용한 모든 계산을 미리 끝낼 수 있기 때문에,  \r\n",
                "앞 부분을 미리 계산 한 뒤 이를 캐싱해두면 계산 시간을 크게 단축시킬 수 있다.  \r\n",
                "\r\n",
                "이러한 계산 생략에도 불구하고 본 알고리즘은 상당한 성능을 보여주었으며 이에 대한 자세한 내용은 [논문 원본](https://arxiv.org/abs/1902.07153)을 참조하길 바란다.  \r\n",
                "\r\n",
                "`in_channels`와 `out_channels` 인자는 Input/Output의 Size를 의미한다.  \r\n",
                "\r\n",
                "`K` 인자는 앞서 설명하였듯이 총 Layer의 수 혹은 hops의 수를 의미한다. 기본 값은 1이다.  \r\n",
                "\r\n",
                "`cached` 인자의 기본 값은 `False`인데, `True`로 설정하면, 첫 수행 후 행렬 계산 식의 결과 값을 캐싱하여 추후에 사용하게 된다.  \r\n",
                "\r\n",
                "이 경우 시간을 단축할 수 있지만 오직 **Transductive** 학습 상황에서만 가능하다.  \r\n",
                "\r\n",
                "왜냐하면 만약 **Inductive**한 상황, 즉 새로운 Node가 진입할 수 있다면 행렬 계산 식의 결과 값을 캐싱하는 것은 의미가 없기 때문이다.  \r\n",
                "\r\n",
                "`add_self_loops` 인자와 `bias` 인자는 다른 Graph Conv Layer들과 마찬가지로 Input Graph에 Self-loop를 추가할지 여부와 bias 추가 여부를 의미한다.  \r\n",
                "\r\n",
                "[공식 문서](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SGConv)를 참조하면 Source 코드 또한 참고할 수 있다.  "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
                "model, data = SG().to(device), data.to(device)\r\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.2, weight_decay=0.005)\r\n",
                "\r\n",
                "\r\n",
                "def train():\r\n",
                "    model.train()\r\n",
                "    optimizer.zero_grad()\r\n",
                "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\r\n",
                "    optimizer.step()\r\n",
                "\r\n",
                "\r\n",
                "def test():\r\n",
                "    model.eval()\r\n",
                "    logits, accs = model(), []\r\n",
                "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\r\n",
                "        pred = logits[mask].max(1)[1]\r\n",
                "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\r\n",
                "        accs.append(acc)\r\n",
                "    return accs"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "best_val_acc = test_acc = 0\r\n",
                "for epoch in range(1, 51):\r\n",
                "    train()\r\n",
                "    train_acc, val_acc, tmp_test_acc = test()\r\n",
                "    if val_acc > best_val_acc:\r\n",
                "        best_val_acc = val_acc\r\n",
                "        test_acc = tmp_test_acc\r\n",
                "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\r\n",
                "    print(log.format(epoch, train_acc, best_val_acc, test_acc))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch: 001, Train: 0.9571, Val: 0.7020, Test: 0.7060\n",
                        "Epoch: 002, Train: 0.9714, Val: 0.7560, Test: 0.7950\n",
                        "Epoch: 003, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
                        "Epoch: 004, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
                        "Epoch: 005, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
                        "Epoch: 006, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
                        "Epoch: 007, Train: 1.0000, Val: 0.7820, Test: 0.8050\n",
                        "Epoch: 008, Train: 1.0000, Val: 0.7820, Test: 0.8050\n",
                        "Epoch: 009, Train: 0.9929, Val: 0.7820, Test: 0.8050\n",
                        "Epoch: 010, Train: 0.9929, Val: 0.7820, Test: 0.8050\n",
                        "Epoch: 011, Train: 0.9929, Val: 0.7820, Test: 0.8050\n",
                        "Epoch: 012, Train: 0.9929, Val: 0.7820, Test: 0.8050\n",
                        "Epoch: 013, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 014, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 015, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 016, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 017, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 018, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 019, Train: 0.9929, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 020, Train: 0.9929, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 021, Train: 0.9929, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 022, Train: 0.9929, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 023, Train: 0.9929, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 024, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 025, Train: 1.0000, Val: 0.7880, Test: 0.8290\n",
                        "Epoch: 026, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 027, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 028, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 029, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 030, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 031, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 032, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 033, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 034, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 035, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 036, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 037, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 038, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 039, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 040, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 041, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 042, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 043, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 044, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 045, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 046, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 047, Train: 1.0000, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 048, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 049, Train: 0.9929, Val: 0.7900, Test: 0.8180\n",
                        "Epoch: 050, Train: 0.9929, Val: 0.7900, Test: 0.8180\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit ('venv': venv)"
        },
        "interpreter": {
            "hash": "a0c8d12882c844609327ff267203d9c0214a9c81f212141ad6ff46d6cf6ed682"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}